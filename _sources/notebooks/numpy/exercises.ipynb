{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tyrj7XXaLx9I"
      },
      "source": [
        "# Ejercicios "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kwQN5-E3Lx9K"
      },
      "outputs": [],
      "source": [
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "98kDIjjPfqtK"
      },
      "source": [
        "---\n",
        "## Convoluciones de arrays"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bCffwlpsf0rF"
      },
      "source": [
        ":::{exercise}\n",
        ":label: chapther2-convolution\n",
        "\n",
        "Dadas dos funciones de variable real $f$ y $g$, definimos la [**convolución**](https://en.wikipedia.org/wiki/Convolution) de $f$ y $g$ como\n",
        "\n",
        "$$\n",
        "(f*g)(x) = \\int_\\mathbb{R} f(t)g(x - t)dt.\n",
        "$$\n",
        "\n",
        "La versión discreta de la anterior definición puede ser la siguiente. Datos $f=(f_0, \\dots, f_{n-1})$ y $g=(g_0, \\dots, g_{m-1})$ dos vectores (representados por arrays unidimensionales) de tamaño $n$ y $m$, respectivamente, definimos el array `conv` de dimensión `n + m - 1` cuya componente $k$ vale \n",
        "\n",
        "$$\n",
        "\\sum_{i + m -1 = k + j}f_ig_j\n",
        "$$\n",
        "\n",
        "para $0 \\leq k \\leq n + m - 1$. \n",
        "\n",
        "Crea una función `conv` que tome como inputs dos arrays y devuelva la convolución de ambos. Por ejemplo \n",
        "\n",
        "```\n",
        "arr1 = np.arange(10)\n",
        "arr2 = np.arange(5) \n",
        "conv(arr1, arr2)\n",
        ">>> [ 0  4 11 20 30 40 50 60 70 80 50 26  9  0]\n",
        "```\n",
        "\n",
        ":::"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z-7rOlfiLx9N"
      },
      "source": [
        ":::{solution} chapther2-convolution\n",
        ":class: dropdown\n",
        "\n",
        "Una primera solución iterando sobre todos las posibles combinaciones de $i$ y $j$ para cada $k$\n",
        "```\n",
        "from itertools import product\n",
        "\n",
        "def conv(f, g):\n",
        "    n = f.shape[0]\n",
        "    m = g.shape[0]\n",
        "    conv_dim = n + m - 1\n",
        "    arr_conv = np.zeros(conv_dim, dtype=f.dtype)\n",
        "    for k in range(conv_dim):\n",
        "        my_gen = (\n",
        "            f[i]*g[j] for i, j in product(range(n), range(m)) \\\n",
        "                if i + m - 1 == j + k\n",
        "        )\n",
        "        arr_conv[k] = sum(my_gen)\n",
        "    return arr_conv\n",
        "```\n",
        "\n",
        "Otra solución más directa considerando la matrix *producto exterior* de $f$ y $g$ y sumando las diagonales \n",
        "\n",
        "```\n",
        "def conv2(f, g):\n",
        "    i = f.shape[0]\n",
        "    j = g.shape[0]\n",
        "    outer_mat = np.outer(f, g).T\n",
        "    c = np.array([np.trace(outer_mat, offset=k) for k in range(-j + 1, i)])\n",
        "    return c\n",
        "```\n",
        "\n",
        ":::\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GenuRidKC9X7"
      },
      "source": [
        "---\n",
        "## Procesando imágenes con numpy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fAFncJvvL9N0"
      },
      "source": [
        ":::{exercise}\n",
        ":label: chapther2-images\n",
        "\n",
        "Una de las posibles técnicas que existen para comprimir una imagen es utilizar [la descomposición SVD (Singular Value Decomposition)](https://en.wikipedia.org/wiki/Singular_value_decomposition) que nos permite expresar una matrix $A$ de dimensiones $n\\times m$ como un producto\n",
        "\n",
        "$$ \n",
        "A = U \\Sigma V^t\n",
        "$$\n",
        "\n",
        "donde $U$ y $V$ son cuadradas de dimensiones $n$ y $m$ respectivamente y $\\Sigma$ es diagonal y está formada por los [valores singulares](https://en.wikipedia.org/wiki/Singular_value) de $A$ ordenados de mayor a menor (siempre son números reales y positivos). \n",
        "\n",
        "Recuerda que una imagen no es más que un conjunto de 3 matrices, cada una representando la intensidad de la grilla de píxeles para cada color (rojo, verde y azul). Una forma de comprimir una imagen consiste en quedarse con los $k$ primeros valores singulares para cada color e intercambiar $k$ por una se las dimensiones que representan el alto o el ancho de la imagen. \n",
        "\n",
        "Crea una función `aproxima_img` que tome un array de dimensión $(3, h, w)$ y devuelva otra imagen aproximada de dimensión $(3, h, w)$ utilizando los k primeros valores singulares. Para ello, \n",
        "1. Utiliza la función `scipy.misc.face` para generar una imagen de prueba, o también puedes importar una utilizando `im = cv2.imread(\"img.jpg\")`. Puedes visualizar imágenes con este formato a través del la función `imshow` de `matplotlib.pyplot` (a veces hay que cambiar de orden los canales).\n",
        "2. Utiliza la función `svd` de `np.linalg` para realizar la descomposición SVD. Mucho cuidado con las dimensiones que espera la función. \n",
        "3. Otras funciones que pueden ser útiles para el ejercicio: `np.transpose`, `np.zeros`, `np.fill_diagonal`, `np.clip`.\n",
        "\n",
        ":::"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        ":::{solution} chapter2-images\n",
        ":class: dropdown\n",
        "\n",
        "Para visualizar la imagen\n",
        "\n",
        "```\n",
        "from scipy.misc import face\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "im = face()\n",
        "plt.imshow(im)\n",
        "```\n",
        "\n",
        "Solución: \n",
        "\n",
        "```\n",
        "def aproxima_img(im: np.ndarray, k: int):\n",
        "        # transponemos la imagen para obtener\n",
        "        # las dimensiones esperadas por np.linalg.svd\n",
        "        im_t = np.transpose(im, (2, 1, 0))\n",
        "        # descomposición SVD\n",
        "        U, s, V = np.linalg.svd(im_t)\n",
        "        # Convertimos s en una matriz compatible \n",
        "        w = im.shape[1]\n",
        "        S = np.zeros((3, w, w))\n",
        "        for canal in range(3):\n",
        "            np.fill_diagonal(S[canal], s[canal])\n",
        "        # calculamos la imagen aproximada \n",
        "        im_c = U @ S[:, :, :k] @ V[:, :k, :]\n",
        "        # vuelta a las dimensiones originales y normalizamos \n",
        "        im_c = np.transpose(im_c, (2, 1, 0))\n",
        "        im_c = (im_c - im_c.min()) / (im_c.max() - im_c.min())\n",
        "        return im_c\n",
        "```\n",
        "\n",
        "La función comienza transponiendo la imagen, lo que cambia el orden de las dimensiones de la imagen. Esto se hace porque la función `np.linalg.svd` espera que las matrices que se le proporcionen tengan las filas como vectores en lugar de las columnas, lo que es el caso de una imagen en formato numpy ndarray.\n",
        "\n",
        "Luego, la función aplica la descomposición SVD a la imagen transpuesta y almacena los valores singulares en la matriz $S$. La descomposición SVD de una matriz m x n es una factorización de la forma $A = USV$\n",
        "\n",
        "donde $A$ es la matriz original, $U$ y $V$ son matrices ortogonales y $S$ es una matriz diagonal con valores singulares en la diagonal. Los valores singulares son los valores positivos raíces cuadradas de los valores propios de la matriz $AA^t$ (si $A$ es real) o la matriz $AA^*$ (si $A$ es compleja), donde $A^t$ es la transpuesta de $A$ y $A^*$ es la conjugada transpuesta de $A$.\n",
        "\n",
        "La matriz `S` se construye de manera que tenga 3 filas y la misma cantidad de columnas que la imagen original. Cada una de las filas de `S` corresponde a un canal de color de la imagen (rojo, verde, azul) y se rellena con los valores singulares correspondientes a ese canal.\n",
        "\n",
        "Luego, la función realiza una multiplicación matricial para proyectar la imagen original en un espacio de menor dimensión. Esto se hace multiplicando la matriz `U` por `S` (truncada a su primeras `k` columnas) y por `V` (truncada a sus primeras `k` filas). Esto se puede escribir como `U * S[:, :, :k] * V[:, :k, :]`. Este producto matricial proyecta la imagen original en un espacio de dimensión `k` en lugar de en el espacio de dimensión original de la imagen.\n",
        "\n",
        "Finalmente, la función transpone la imagen resultante, la normaliza entre 0 y 1 y la devuelve. La normalización consiste en restar el valor mínimo de la imagen a cada pixel de la imagen y luego dividir el resultado por la diferencia entre el valor máximo y el valor mínimo de la imagen. Esto garantiza que todos los valores de la imagen queden entre 0 y 1.\n",
        "\n",
        "\n",
        ":::\n"
      ],
      "metadata": {
        "id": "EgiAudzRuqul"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_AEvYyJYGJ7W"
      },
      "source": [
        ":::{exercise}\n",
        ":label: chapter2-images-convolution\n",
        "\n",
        "Importa una imagen de tu elección utilizando la función `imread` de la librería `cv2`. Crea un array `kernel` de dimensión $(n, n)$ y realiza la convolución de tu imagen con `kernel` mediante la función [`scipy.signal.convolve2d`](https://docs.scipy.org/doc/scipy/reference/generated/scipy.signal.convolve2d.html#scipy.signal.convolve2d) (parámetro `mode='same'`). Si tu imagen tiene varios canales para los colores, aplica el mismo kernel a cada canal.\n",
        "\n",
        "Algunos ejemplos interesantes de kernel pueden ser los siguientes:\n",
        "\n",
        "- $n = 3$ con valores \n",
        "\n",
        "$$\n",
        "\\begin{pmatrix}\n",
        "-3 & 0 & 3\\\\\n",
        "-10 & 0 & 10\\\\\n",
        "-3 & 0 & 3\n",
        "\\end{pmatrix} \n",
        "$$\n",
        "\n",
        "- transpuesta del anterior, \n",
        "\n",
        "$$\n",
        "\\begin{pmatrix}\n",
        "-3 & -10 & -3\\\\\n",
        "0 & 0 & 0\\\\\n",
        "3 & 10 & 3\n",
        "\\end{pmatrix} \n",
        "$$\n",
        "\n",
        "- $n \\approx 50$, generados con `scipy.signal.windows.gaussian` (puedes utilizar la función `np.outer` para realizar un producto exterior)\n",
        "\n",
        "- Operador complejo de Sharr\n",
        "```\n",
        "scharr = np.array([[ -3-3j, 0-10j,  +3 -3j],\n",
        "\n",
        "                   [-10+0j, 0+ 0j, +10 +0j],\n",
        "\n",
        "                   [ -3+3j, 0+10j,  +3 +3j]])\n",
        "```\n",
        "Puedes visualizar las imágenes con `matplotlib.pyplot.imshow`.\n",
        "\n",
        ":::"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## Regresión Lineal"
      ],
      "metadata": {
        "id": "q0HI5tjPMR4j"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        ":::{exercise}\n",
        ":label: chapter2-linear-regression\n",
        "\n",
        "Considera un modelo de regresión lineal que consiste en estimar una variable $y$ como una suma ponderada de un cojunto de variables regresoras \n",
        "\n",
        "$$\n",
        "\\hat{y} = \\theta_0 + \\theta_1x_1 + \\dots \\theta_nx_n\n",
        "$$\n",
        "\n",
        "donde \n",
        "\n",
        "- $n$ es el conjunto de variables regresoras o *features*, $x_i$ el valor correspondiente.\n",
        "- $\\hat{y}$ es el valor predicho. \n",
        "- $\\theta_i$ son parámetros del modelo para $0 \\leq i \\leq n$.  \n",
        "\n",
        "Podemos expresar dicha ecuación en formato matricial como\n",
        "\n",
        "$$\n",
        "\\hat{y} = \n",
        "\\begin{pmatrix}\n",
        "1 & x_1 & \\cdots & x_n\n",
        "\\end{pmatrix} \n",
        "\\begin{pmatrix}\n",
        "\\theta_0 \\\\\n",
        "\\theta_1 \\\\\n",
        "\\vdots \\\\\n",
        "\\theta_n\n",
        "\\end{pmatrix} \n",
        "=\n",
        "\\boldsymbol{x} \\cdot \\boldsymbol{\\theta}.\n",
        "$$\n",
        "\n",
        "Dado un conjunto de $m$ observaciones, nuestro objetivo es encontrar $\\boldsymbol{\\theta}$ tal que se minimice nuestra aproximación lineal en términos de menores cuadrados \n",
        "\n",
        "$$\n",
        "\\frac{1}{m}\\sum_{i=1}^{m} \n",
        "(\\boldsymbol{x}_i \\cdot \\boldsymbol{\\theta} - y_i)^2.\n",
        "$$\n",
        "\n",
        "El valor óptimo de los parámetros se puede calcular directamente \n",
        "\n",
        "$$\n",
        "\\hat{\\theta} = (\\boldsymbol{X}^t\\boldsymbol{X})^{-1}\\boldsymbol{X}^ty\n",
        "$$\n",
        "\n",
        "donde \n",
        "\n",
        "$$\n",
        "\\boldsymbol{X} = \n",
        "\\begin{pmatrix}\n",
        "1 & x_{11} & \\cdots & x_{1n} \\\\\n",
        "1 & x_{21} & \\cdots & x_{2n} \\\\\n",
        "\\vdots & \\vdots & \\cdots & \\vdots \\\\\n",
        "1 & x_{m1} & \\cdots & x_{mn} \n",
        "\\end{pmatrix}\n",
        "$$\n",
        "\n",
        "es el conjunto de observaciones de las variables regresoras e\n",
        "\n",
        "$$\n",
        "\\hat{y}=\n",
        "\\begin{pmatrix}\n",
        "y_0 \\\\\n",
        "y_1 \\\\\n",
        "\\vdots \\\\\n",
        "y_n\n",
        "\\end{pmatrix}\n",
        "$$\n",
        "\n",
        "es el conjunto de observaciones de la variable objetivo.\n",
        "\n",
        "\n",
        "Crea una clase `RegresionLineal` con dos métodos, \n",
        "- `entrena`: toma como parámetros `X` e `y`, observaciones de las variables regresoras y objetivo, respectivamente, y calcula los coeficientes de la regresión lineal y los guarda en un atributo `_theta`. \n",
        "- `transforma`: toma como parámetro una serie de observaciones nuevas `X` y devuelve una estimación `y_hat` de la varible objetivo utilizando el método descrito anteriormente. \n",
        "\n",
        "Funciones que puede ser de ayuda: `np.linalg.inv`, `np.linalg.pinv`, `np.vstack`, `np.hstack`.\n",
        "\n",
        ":::"
      ],
      "metadata": {
        "id": "OnZBQDQ-tK3O"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        ":::{solution} my-exercise\n",
        ":class: dropdown\n",
        "\n",
        "```\n",
        "import numpy as np\n",
        "\n",
        "class RegresionLineal:\n",
        "\n",
        "    def entrena(self, X, y):\n",
        "        # Agregamos una columna de unos a X para tener un término independiente\n",
        "        X = np.hstack([np.ones((X.shape[0], 1)), X])\n",
        "\n",
        "        # Calculamos los coeficientes de la regresión lineal utilizando la fórmula normal\n",
        "        self._theta = np.linalg.inv(X.T.dot(X)).dot(X.T).dot(y)\n",
        "\n",
        "    def transforma(self, X):\n",
        "        # Agregamos una columna de unos a X para tener un término independiente\n",
        "        X = np.hstack([np.ones((X.shape[0], 1)), X])\n",
        "\n",
        "        # Utilizamos los coeficientes entrenados para hacer una predicción\n",
        "        y_hat = X.dot(self._theta)\n",
        "\n",
        "        return y_hat\n",
        "```\n",
        "\n",
        ":::\n"
      ],
      "metadata": {
        "id": "GgUgJvo1xa7h"
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3.9.1 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.1"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "397704579725e15f5c7cb49fe5f0341eb7531c82d19f2c29d197e8b64ab5776b"
      }
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}